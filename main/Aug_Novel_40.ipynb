{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Aug_Novel_40.ipynb","provenance":[{"file_id":"1snR13NTnzQL_zu8JAqa7POOm3_3LuZkT","timestamp":1607543875710}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"G6DaudkwiI68","executionInfo":{"status":"ok","timestamp":1607595228285,"user_tz":-330,"elapsed":6011,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}}},"source":["import numpy as np\r\n","import pandas as pd\r\n","import matplotlib.pyplot as plt\r\n","import plotly.express as px\r\n","\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WERSAlkyiJnO","executionInfo":{"status":"ok","timestamp":1607595280866,"user_tz":-330,"elapsed":58581,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}},"outputId":"2e8a9b95-dad0-4a67-e82f-ebcf8b95d823"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive',force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zfbvakRgiLez","executionInfo":{"status":"ok","timestamp":1607595324678,"user_tz":-330,"elapsed":102384,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}},"outputId":"5b029e21-8718-4829-a487-19e0701eb94a"},"source":["df = pd.read_csv('/content/drive/MyDrive/ML/dataset/aug_age_gender.csv')\r\n","print(df.pixels.nunique())\r\n","#Finding no. of null values\r\n","print(df.pixels.isnull().sum())\r\n","#Finding repaeted rows\r\n","df_repeated = df.groupby('pixels').filter(lambda x: len(x) > 1)\r\n","print(df_repeated.head())\r\n","\r\n","#FInding the no of unique rows that are repeated\r\n","print(len(df_repeated.groupby(['pixels'])))\r\n","print(len(df_repeated.groupby(['pixels', 'age', 'ethnicity', 'gender'])))\r\n","\r\n","#Since there is an abnormality & confusion n the data lebels as seen by printing the values, we choose to drop the repeated rows = 765 directly. So are choosing 22940 rows for our model.\r\n","df_final = df.groupby('pixels').filter(lambda x: len(x) == 1)\r\n","\r\n","#Converting pixels to array of pixels\r\n","df_final['pixels'] = df_final['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\"))\r\n","\r\n","#printing rows and colums\r\n","print(df.shape)\r\n","print(df_final.head())\r\n","# normalizing pixels data\r\n","df_final['pixels'] = df_final['pixels'].apply(lambda x: x/255)\r\n","df_final = df_final.sample(frac=1).reset_index(drop=True)\r\n","#COnverting to list\r\n","X = np.array(df_final['pixels'].tolist())\r\n","print(X.shape)\r\n","print(X[0])\r\n","print(len(X[0]))\r\n","print(X.shape[0])\r\n","# Converting pixels from 1D to 3D\r\n","X = X.reshape(X.shape[0],48,48,1)\r\n","print(X.shape[0])\r\n","print(X[0])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["49909\n","0\n","     age  ...                                             pixels\n","135    1  ...  43 39 31 37 33 31 39 43 70 93 118 131 153 116 ...\n","302    1  ...  233 214 152 91 49 33 56 94 109 104 99 92 88 94...\n","349    1  ...  254 238 205 193 178 195 196 196 187 183 189 17...\n","486    1  ...  196 196 197 197 200 201 202 202 200 201 201 20...\n","497    1  ...  196 196 197 197 200 201 202 202 200 201 201 20...\n","\n","[5 rows x 5 columns]\n","375\n","641\n","(50299, 5)\n","   age  ...                                             pixels\n","0    1  ...  [129.0, 128.0, 128.0, 126.0, 127.0, 130.0, 133...\n","1    1  ...  [164.0, 74.0, 111.0, 168.0, 169.0, 171.0, 175....\n","2    1  ...  [67.0, 70.0, 71.0, 70.0, 69.0, 67.0, 70.0, 79....\n","3    1  ...  [193.0, 197.0, 198.0, 200.0, 199.0, 200.0, 202...\n","4    1  ...  [202.0, 205.0, 209.0, 210.0, 209.0, 209.0, 210...\n","\n","[5 rows x 5 columns]\n","(49534, 2304)\n","[0.         0.         0.         ... 0.20784314 0.20392157 0.2       ]\n","2304\n","49534\n","49534\n","[[[0.        ]\n","  [0.        ]\n","  [0.        ]\n","  ...\n","  [0.5686275 ]\n","  [0.6313726 ]\n","  [0.6784314 ]]\n","\n"," [[0.        ]\n","  [0.        ]\n","  [0.        ]\n","  ...\n","  [0.5921569 ]\n","  [0.6509804 ]\n","  [0.67058825]]\n","\n"," [[0.        ]\n","  [0.        ]\n","  [0.        ]\n","  ...\n","  [0.6156863 ]\n","  [0.67058825]\n","  [0.65882355]]\n","\n"," ...\n","\n"," [[0.11372549]\n","  [0.18431373]\n","  [0.21568628]\n","  ...\n","  [0.19607843]\n","  [0.2       ]\n","  [0.21176471]]\n","\n"," [[0.14117648]\n","  [0.2       ]\n","  [0.22352941]\n","  ...\n","  [0.19607843]\n","  [0.19215687]\n","  [0.1882353 ]]\n","\n"," [[0.16470589]\n","  [0.20784314]\n","  [0.23137255]\n","  ...\n","  [0.20784314]\n","  [0.20392157]\n","  [0.2       ]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DRslIK0jiSu1","executionInfo":{"status":"ok","timestamp":1607595325814,"user_tz":-330,"elapsed":103513,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}}},"source":["import seaborn as sns\r\n","sns.set()\r\n","\r\n","from keras.models import Sequential\r\n","from keras.layers import Conv2D, Dropout, BatchNormalization, Flatten, Dense, MaxPooling2D\r\n","from keras.utils import to_categorical\r\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\r\n","from keras.optimizers import Adam\r\n","\r\n","from sklearn.metrics import mean_absolute_error, confusion_matrix, classification_report\r\n","from sklearn.model_selection import train_test_split"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"67MEoLwdiWMI","executionInfo":{"status":"ok","timestamp":1607595325815,"user_tz":-330,"elapsed":103508,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}}},"source":["y_new = np.array(df_final[['gender', 'ethnicity', 'age']])\r\n","#Splitting the data\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.2, random_state=42)\r\n","X_train, X_cv, y_train, y_cv = train_test_split(X_train,y_train,test_size = 0.25,train_size =0.75)\r\n","\r\n","y_gender_train = y_train[:,0]\r\n","y_gender_test = y_test[:,0]\r\n","y_gender_cv = y_cv[:,0]\r\n","\r\n","y_age_train = y_train[:,2]\r\n","y_age_test = y_test[:,2]\r\n","y_age_cv = y_cv[:,2]\r\n","\r\n","y_ethnicity_train = y_train[:,1]\r\n","y_ethnicity_test = y_test[:,1]\r\n","y_ethnicity_cv = y_cv[:,1]\r\n","\r\n","#FInding the position to slice\r\n","eth_train_len = len(y_ethnicity_train)\r\n","eth_cv_len=len(y_ethnicity_cv)\r\n","#COncatenating the dataset\r\n","y_ethnicity_concat = np.concatenate((y_ethnicity_train,y_ethnicity_cv, y_ethnicity_test))\r\n","\r\n","#COne hot encoding\r\n","y_ethnicity = to_categorical(y_ethnicity_concat)\r\n","\r\n","y_ethnicity_train = y_ethnicity[:eth_train_len]\r\n","y_ethnicity_cv=y_ethnicity[eth_train_len:(eth_train_len+eth_cv_len)]\r\n","y_ethnicity_test = y_ethnicity[(eth_train_len+eth_cv_len):]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wp0ut2fYiZSN","executionInfo":{"status":"ok","timestamp":1607595325816,"user_tz":-330,"elapsed":103503,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}}},"source":["#import kerastuner as kt\r\n","import tensorflow as tf\r\n","from tensorflow import keras\r\n","from tensorflow.keras import layers\r\n","from tensorflow.keras.models import Sequential\r\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\r\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\r\n","from tensorflow.keras.optimizers import SGD\r\n","from tensorflow.keras.layers import BatchNormalization\r\n","from tensorflow.keras.layers import LeakyReLU\r\n","from tensorflow.keras.models import clone_model\r\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\r\n","from tensorflow.keras.callbacks import EarlyStopping\r\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n","from tensorflow.keras.utils import plot_model\r\n","\r\n","import keras\r\n","import IPython"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PXZiXAAbici9","executionInfo":{"status":"ok","timestamp":1607595325817,"user_tz":-330,"elapsed":103497,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}},"outputId":"c5533dfe-40f3-403d-8d46-aec58c0fc525"},"source":["inputs = tf.keras.Input(shape=(48, 48, 1))\r\n","x = inputs\r\n","\r\n","x = Conv2D(160, kernel_size=(3,3),padding='same')(x)\r\n","x = tf.keras.layers.BatchNormalization()(x)\r\n","x = tf.keras.layers.LeakyReLU(0.3)(x)\r\n","\r\n","x = tf.keras.layers.MaxPool2D()(x)\r\n","\r\n","x = Conv2D(192, kernel_size=(3,3),padding='same')(x)\r\n","x = tf.keras.layers.BatchNormalization()(x)\r\n","x = tf.keras.layers.LeakyReLU(0.3)(x)\r\n","\r\n","x = tf.keras.layers.AvgPool2D()(x)\r\n","\r\n","x = Conv2D(224, kernel_size=(3,3),padding='same')(x)\r\n","x = tf.keras.layers.BatchNormalization()(x)\r\n","x = tf.keras.layers.LeakyReLU(0.1)(x)\r\n","\r\n","x = tf.keras.layers.MaxPool2D()(x)\r\n","\r\n","x = Conv2D(224, kernel_size=(3,3),padding='same')(x)\r\n","x = tf.keras.layers.BatchNormalization()(x)\r\n","x = tf.keras.layers.LeakyReLU(0.1)(x)\r\n","\r\n","x = tf.keras.layers.AvgPool2D()(x)\r\n","\r\n","x = Conv2D(224, kernel_size=(3,3),padding='same')(x)\r\n","x = tf.keras.layers.BatchNormalization()(x)\r\n","x = tf.keras.layers.LeakyReLU(0.1)(x)\r\n","\r\n","x = tf.keras.layers.MaxPool2D()(x)\r\n","\r\n","x = tf.keras.layers.GlobalAvgPool2D()(x)\r\n","\r\n","x = layers.Flatten()(x)\r\n","x = layers.Dense(896,activation='relu')(x)\r\n","x = tf.keras.layers.Dropout(0.4)(x)\r\n","x = layers.Dense(896,activation='relu')(x)\r\n","\r\n","#bottleneck =  tf.keras.layers.GlobalMaxPool2D()(x)\r\n","out_gender = layers.Dense(1, activation='sigmoid', name='gender_out')(x) ## output binaire\r\n","out_ethnicity = layers.Dense(5, activation='sigmoid', name='ethnicity_out')(x) ## output catégoriel\r\n","out_age=layers.Dense(1,activation='linear', name='age_out')(x) ## output continue\r\n","\r\n","\r\n","model = tf.keras.Model(inputs=inputs, outputs=[out_gender, out_ethnicity, out_age])\r\n","model.compile(\r\n","      optimizer='rmsprop',\r\n","        loss={'gender_out':'BinaryCrossentropy',\r\n","              'ethnicity_out':'categorical_crossentropy',\r\n","              'age_out':'mse'},\r\n","        metrics={'gender_out':'accuracy',\r\n","                 'ethnicity_out':'accuracy',\r\n","                 'age_out':'mae'})\r\n","model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 48, 48, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 48, 48, 160)  1600        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 48, 48, 160)  640         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","leaky_re_lu (LeakyReLU)         (None, 48, 48, 160)  0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 24, 24, 160)  0           leaky_re_lu[0][0]                \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 24, 24, 192)  276672      max_pooling2d[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 24, 24, 192)  768         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)       (None, 24, 24, 192)  0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","average_pooling2d (AveragePooli (None, 12, 12, 192)  0           leaky_re_lu_1[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 12, 12, 224)  387296      average_pooling2d[0][0]          \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 12, 12, 224)  896         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)       (None, 12, 12, 224)  0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 224)    0           leaky_re_lu_2[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 6, 6, 224)    451808      max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 6, 6, 224)    896         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)       (None, 6, 6, 224)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","average_pooling2d_1 (AveragePoo (None, 3, 3, 224)    0           leaky_re_lu_3[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 3, 3, 224)    451808      average_pooling2d_1[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 3, 3, 224)    896         conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)       (None, 3, 3, 224)    0           batch_normalization_4[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 224)    0           leaky_re_lu_4[0][0]              \n","__________________________________________________________________________________________________\n","global_average_pooling2d (Globa (None, 224)          0           max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 224)          0           global_average_pooling2d[0][0]   \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 896)          201600      flatten[0][0]                    \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 896)          0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 896)          803712      dropout[0][0]                    \n","__________________________________________________________________________________________________\n","gender_out (Dense)              (None, 1)            897         dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","ethnicity_out (Dense)           (None, 5)            4485        dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","age_out (Dense)                 (None, 1)            897         dense_1[0][0]                    \n","==================================================================================================\n","Total params: 2,584,871\n","Trainable params: 2,582,823\n","Non-trainable params: 2,048\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cehJ3G43jxh0","executionInfo":{"status":"ok","timestamp":1607595325818,"user_tz":-330,"elapsed":103491,"user":{"displayName":"ROHAN KUMAR","photoUrl":"","userId":"07126956216912620175"}}},"source":["batch_size = 32\r\n","epochs = 40\r\n","\r\n","\r\n","history_list = []"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fc0m4bEJjx9g","outputId":"a7bc719f-9de8-49e0-b43a-62138266aea8"},"source":["history = model.fit(X_train, {'gender_out': y_gender_train, 'ethnicity_out': y_ethnicity_train, 'age_out': y_age_train},\r\n","                         batch_size=batch_size,\r\n","                         epochs = epochs, validation_data = (X_cv, [y_gender_cv, y_ethnicity_cv, y_age_cv]),\r\n","                         steps_per_epoch=(X_train.shape[0] // batch_size)\r\n","                         )\r\n","\r\n","history_list.append(history)\r\n","export_path='/content/drive/MyDrive/ML/novel_40_aug'\r\n","tf.saved_model.save(model, export_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n","928/928 [==============================] - 1283s 1s/step - loss: 161.8076 - gender_out_loss: 0.6754 - ethnicity_out_loss: 1.5161 - age_out_loss: 159.6160 - gender_out_accuracy: 0.6012 - ethnicity_out_accuracy: 0.3377 - age_out_mae: 8.6928 - val_loss: 159.1363 - val_gender_out_loss: 0.6698 - val_ethnicity_out_loss: 1.7582 - val_age_out_loss: 156.7083 - val_gender_out_accuracy: 0.6257 - val_ethnicity_out_accuracy: 0.2649 - val_age_out_mae: 7.7684\n","Epoch 2/40\n","928/928 [==============================] - 1271s 1s/step - loss: 103.4347 - gender_out_loss: 0.6512 - ethnicity_out_loss: 1.4786 - age_out_loss: 101.3050 - gender_out_accuracy: 0.6309 - ethnicity_out_accuracy: 0.3662 - age_out_mae: 6.6953 - val_loss: 7016.4619 - val_gender_out_loss: 1.7554 - val_ethnicity_out_loss: 3.1474 - val_age_out_loss: 7011.5620 - val_gender_out_accuracy: 0.4643 - val_ethnicity_out_accuracy: 0.2015 - val_age_out_mae: 82.0590\n","Epoch 3/40\n","928/928 [==============================] - 1273s 1s/step - loss: 84.8444 - gender_out_loss: 0.6359 - ethnicity_out_loss: 1.4320 - age_out_loss: 82.7763 - gender_out_accuracy: 0.6462 - ethnicity_out_accuracy: 0.4058 - age_out_mae: 6.0738 - val_loss: 708.6643 - val_gender_out_loss: 0.9659 - val_ethnicity_out_loss: 1.7227 - val_age_out_loss: 705.9756 - val_gender_out_accuracy: 0.4658 - val_ethnicity_out_accuracy: 0.2829 - val_age_out_mae: 22.9965\n","Epoch 4/40\n","  5/928 [..............................] - ETA: 14:41 - loss: 65.1380 - gender_out_loss: 0.6182 - ethnicity_out_loss: 1.3711 - age_out_loss: 63.1487 - gender_out_accuracy: 0.6711 - ethnicity_out_accuracy: 0.3947 - age_out_mae: 5.5095"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mME8-qInBMbs"},"source":["export_path='/content/drive/MyDrive/ML/novel_15'\r\n","tf.saved_model.save(model, export_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OFKKVejBXaa"},"source":["export_path='/content/drive/MyDrive/ML/novel_15'\r\n","loaded_model=tf.keras.models.load_model(export_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFz1hvJ9CJre"},"source":["from matplotlib import pyplot as plt\r\n","\r\n","def plot_loss(his, epoch, title):\r\n","    plt.figure()\r\n","    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\r\n","    plt.plot(np.arange(0, epoch), his.history['gender_out_loss'], label='train_gender_loss')\r\n","    plt.plot(np.arange(0, epoch), his.history['ethnicity_out_loss'], label='train_ethnicity_loss')\r\n","    plt.plot(np.arange(0, epoch), his.history['age_out_loss'], label='train_age_loss')\r\n","    \r\n","    plt.plot(np.arange(0, epoch), his.history['val_gender_out_loss'], label='val_train_gender_loss')\r\n","    plt.plot(np.arange(0, epoch), his.history['val_ethnicity_out_loss'], label='val_train_ethnicity_loss')\r\n","    plt.plot(np.arange(0, epoch), his.history['val_age_out_loss'], label='val_train_age_loss')\r\n","    \r\n","    plt.title(title)\r\n","    plt.xlabel('Epoch #')\r\n","    plt.ylabel('Loss')\r\n","    plt.legend(loc='upper right')\r\n","    plt.show()\r\n","def plot_acc(his, epoch, title):\r\n","    plt.figure()\r\n","    plt.plot(np.arange(0, epoch), his.history['gender_out_accuracy'], label='train_gender_acc')\r\n","    plt.plot(np.arange(0, epoch), his.history['ethnicity_out_accuracy'], label='train_ethnicity_accuracy')\r\n","        \r\n","    plt.plot(np.arange(0, epoch), his.history['val_gender_out_accuracy'], label='val_gender_acc')\r\n","    plt.plot(np.arange(0, epoch), his.history['val_ethnicity_out_accuracy'], label='val_ethnicity_accuracy')\r\n","\r\n","\r\n","    plt.title(title)\r\n","    plt.xlabel('Epoch #')\r\n","    plt.ylabel('Accuracy')\r\n","    plt.legend(loc='lower right')\r\n","    plt.show()\r\n","def plot_MSE(his, epoch, title):\r\n","    plt.figure()\r\n","    plt.plot(np.arange(0, epoch), his.history['age_out_mae'], label='train_age_mae')\r\n","    plt.plot(np.arange(0, epoch), his.history['val_age_out_mae'], label='val_age_mae')\r\n","\r\n","    plt.title(title)\r\n","    plt.xlabel('Epoch #')\r\n","    plt.ylabel('Mean Absolute Error')\r\n","    plt.legend(loc='upper right')\r\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBa4x5KACk0A"},"source":["plot_loss(history_list[0], epochs, f'Training Dataset: {0}')\r\n","plot_acc(history_list[0], epochs, f'Training Dataset: {0}')\r\n","plot_MSE(history_list[0], epochs, f'Training Dataset: {0}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_CpP7KLEJsl"},"source":["pred = loaded_model.predict(X_test)\r\n","\r\n","test_loss,test_gender_loss, test_ethnicity_loss, test_age_loss, test_gender_acc,test_ethnicity_acc,test_age_mae = loaded_model.evaluate(X_test, [y_gender_test, y_ethnicity_test, y_age_test], verbose=0)\r\n","print(f'\\nTest gender accuracy: {test_gender_acc}')\r\n","print(f'\\nTest ethnicity accuracy: {test_ethnicity_acc}')\r\n","print(f'\\nTest age MAE: {test_age_mae}')"],"execution_count":null,"outputs":[]}]}